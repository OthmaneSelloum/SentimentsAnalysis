# SentimentsAnalysis
# ğŸ“Š Sentiment Analysis Project  

This project implements sentiment analysis on textual data using <b>Deep Learning models</b>, specifically a **Convolutional Neural Network (CNN)** and a **Long Short-Term Memory (LSTM)** network.  

---

## ğŸŒŸ Features  

- ğŸ“‚ **Dataset Handling**:  
  - Loaded and prepared a labeled dataset from IMDB for training and testing. 

- ğŸ”„ **Data Preprocessing**:  
  - ğŸ“ **Tokenization**: Splitting text into tokens.  
  - ğŸ›‘ **Stopword Removal**: Removing unnecessary words for better analysis.  
  - âœ‚ï¸ **Text Cleaning**: Stripping special characters and numbers.  
  - ğŸ“ **Padding**: Standardizing sequence lengths for model compatibility.  

- ğŸ’¡ **Embeddings**:  
  - Generated numerical representations of words using embedding layers(GloVe) to capture semantic relationships.  

- ğŸ§  **Model Training**:  
  - Trained CNN and LSTM models on the processed dataset.  

- ğŸ“ˆ **Evaluation**:  
  - Visualized results and evaluated model performance using key metrics.  

---

## ğŸ“¦ Requirements  

To run the project, you need the following libraries:  

- `numpy`  
- `pandas`  
- `matplotlib`  
- `seaborn`  
- `nltk`  
- `tensorflow-keras`  
- `scikit-learn`  

## ğŸ“‚ Project Structure

Sentiments Analysis/
â”œâ”€â”€ data/                    # Dataset folder
â”œâ”€â”€ Sentiments Analysis.ipynb # Jupyter Notebook
â”œâ”€â”€ models/                  # Saved trained models (optional)
â””â”€â”€ README.md                # Project Documentation

---

### ğŸ“‹ **Model Training Report**

In this project, we trained two models, a **Convolutional Neural Network (CNN)** and a **Long Short-Term Memory (LSTM)** network, on our dataset to perform sentiment analysis. Below is a detailed summary of our observations:  

---

#### âš¡ **1. CNN Model (Convolutional Neural Network)**  
- **ğŸ”§ Architecture**:  
  - The CNN model featured an **embedding layer**, followed by a 1D convolutional layer, **Global Max Pooling**, and a dense output layer.  
- **ğŸ“ˆ Performance**:  
  - The CNN model achieved high accuracy on the training set during training.  
  - However, we observed significant **overfitting**: performance on the validation set degraded as training progressed. This suggests the model struggled to generalize to unseen data, likely due to its reliance on localized patterns in the dataset.  

---

#### ğŸŒŠ **2. LSTM Model (Long Short-Term Memory)**  
- **ğŸ”§ Architecture**:  
  - The LSTM model included an **embedding layer**, followed by an LSTM layer and a dense output layer.  
- **ğŸ“ˆ Performance**:  
  - The LSTM model demonstrated better **generalization** compared to the CNN.  
  - Training and validation performance were closely aligned, indicating a **lower risk of overfitting**. Its ability to capture sequential dependencies and long-term relationships in the data made it more effective for this task.  

---

#### âœ… **Conclusion**  
After careful analysis, we decided to proceed with the **LSTM model** for predictions.  
ğŸ‘‰ It better handles the sequential nature of the dataset and avoids the overfitting issues encountered with the CNN model. This choice ensures better performance and generalization to unseen data.  

----

## **ğŸ“ Notes**
This project demonstrates the integration of machine learning with natural language processing for sentiment classification. Further enhancements can include hyperparameter tuning and experimenting with other models.
