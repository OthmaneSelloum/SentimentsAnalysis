# SentimentsAnalysis
# ğŸ“Š Sentiment Analysis Project  

This project implements sentiment analysis on textual data using <b>Deep Learning models</b>, specifically a **Convolutional Neural Network (CNN)** and a **Long Short-Term Memory (LSTM)** network.  

---

## ğŸŒŸ Features  

- ğŸ“‚ **Dataset Handling**:  
  - Loaded and prepared a labeled dataset from IMDB for training and testing. 

- ğŸ”„ **Data Preprocessing**:  
  - ğŸ“ **Tokenization**: Splitting text into tokens.  
  - ğŸ›‘ **Stopword Removal**: Removing unnecessary words for better analysis.  
  - âœ‚ï¸ **Text Cleaning**: Stripping special characters and numbers.  
  - ğŸ“ **Padding**: Standardizing sequence lengths for model compatibility.  

- ğŸ’¡ **Embeddings**:  
  - Generated numerical representations of words using embedding layers to capture semantic relationships.  

- ğŸ§  **Model Training**:  
  - Trained CNN and LSTM models on the processed dataset.  

- ğŸ“ˆ **Evaluation**:  
  - Visualized results and evaluated model performance using key metrics.  

---

## ğŸ“¦ Requirements  

To run the project, you need the following libraries:  

- `numpy`  
- `pandas`  
- `matplotlib`  
- `seaborn`  
- `nltk`  
- `tensorflow`  
- `scikit-learn`  

## ğŸ“‚ Project Structure
plaintext
Copier le code
Sentiments Analysis/
â”œâ”€â”€ data/                    # Dataset folder
â”œâ”€â”€ Sentiments Analysis.ipynb # Jupyter Notebook
â”œâ”€â”€ models/                  # Saved trained models (optional)
â””â”€â”€ README.md                # Project Documentation

### ğŸ“‹ **Rapport d'EntraÃ®nement des ModÃ¨les**

Dans ce projet, nous avons entraÃ®nÃ© deux modÃ¨les, un **Convolutional Neural Network (CNN)** et un **Long Short-Term Memory (LSTM)**, pour effectuer une analyse de sentiments sur notre dataset. Voici un rÃ©sumÃ© dÃ©taillÃ© de nos observations :  

---

#### âš¡ **1. ModÃ¨le CNN (Convolutional Neural Network)**  
- **ğŸ”§ Architecture** :  
  - Une couche d'**embedding** suivie d'une couche de convolution 1D, d'un **Global Max Pooling** et d'une couche dense pour la sortie.  
- **ğŸ“ˆ Performance** :  
  - Pendant l'entraÃ®nement, le modÃ¨le CNN a obtenu une haute prÃ©cision sur l'ensemble d'entraÃ®nement.  
  - Cependant, nous avons observÃ© un **surapprentissage** significatif : les performances sur l'ensemble de validation ont commencÃ© Ã  se dÃ©grader. Cela montre que le modÃ¨le avait du mal Ã  se gÃ©nÃ©raliser Ã  des donnÃ©es non vues, probablement en raison de sa dÃ©pendance Ã  des motifs localisÃ©s dans les donnÃ©es.  

---

#### ğŸŒŠ **2. ModÃ¨le LSTM (Long Short-Term Memory)**  
- **ğŸ”§ Architecture** :  
  - Une couche d'**embedding**, suivie d'une couche LSTM et d'une couche dense pour la sortie.  
- **ğŸ“ˆ Performance** :  
  - Le modÃ¨le LSTM a montrÃ© une meilleure capacitÃ© de **gÃ©nÃ©ralisation** par rapport au CNN.  
  - Les performances sur les ensembles d'entraÃ®nement et de validation Ã©taient alignÃ©es, ce qui indique un **faible risque de surapprentissage**. GrÃ¢ce Ã  sa capacitÃ© Ã  capturer les relations sÃ©quentielles et les dÃ©pendances Ã  long terme dans les donnÃ©es, il s'est rÃ©vÃ©lÃ© plus efficace.  

---

#### âœ… **Conclusion**  
AprÃ¨s analyse, nous avons choisi de continuer avec le **modÃ¨le LSTM** pour nos prÃ©dictions.  
ğŸ‘‰ Il est mieux adaptÃ© Ã  la nature sÃ©quentielle du dataset et Ã©vite le problÃ¨me de surapprentissage rencontrÃ© avec le modÃ¨le CNN. Cette dÃ©cision garantit de meilleures performances et une meilleure capacitÃ© de gÃ©nÃ©ralisation aux nouvelles donnÃ©es.  

## **ğŸ“ Notes**
This project demonstrates the integration of machine learning with natural language processing for sentiment classification. Further enhancements can include hyperparameter tuning and experimenting with other models.
